---
title: "Eksplorasi Data dari Playstor"
output: 
 html_notebook:
    toc: true
    toc_depth: 3
    toc_float: true
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

# Library

```{r}
# Runing RJava
if (Sys.info()['sysname'] == 'Darwin') {
  libjvm <- paste0(system2('/usr/libexec/java_home',stdout = TRUE)[1],'/jre/lib/server/libjvm.dylib')
  message (paste0('Load libjvm.dylib from: ',libjvm))
  dyn.load(libjvm)
}

library(lubridate)
library(tidyverse)
library(tidytext)
library(stringr)
library(tm)
library(reshape2)
library(scales)
library(AnomalyDetection)
library(igraph)
library(ggraph)
library(topicmodels)
library(SnowballC)
library(RWeka) 
```

# Tentang Data
Data berupa komentar terhadap dua aplikasi dari gojek di playstore, yaitu untuk customer dan driver. 

```{r}
dirwd <- paste(getwd(),"/wrangled data proj-2/",sep='')
ps_gojek <- read.csv(paste(dirwd,"playstore-gojek.csv",sep=''), 
                     header = TRUE, sep = ",", stringsAsFactors = FALSE)
```

# Perbandingan Jumlah

```{r}
ps_gojek %>%
  group_by(aplikasi) %>%
  count(aplikasi) %>%
  ggplot(aes(aplikasi, n)) + geom_col() +
  labs( x = "Aplikasi", y = "Jumlah Komentar")
```

Data dari `gojek_customer` lebih tinggi dibanding `gojek_driver`

# Frekuensi term 
Gambar di bawah ini menunjukkan perbandingan kata yang digunakan dalam komentar untuk dua aplikasi. 

```{r}
ps_gojek %>%
  select(aplikasi, clean_text) %>%
  group_by(aplikasi) %>%
  unnest_tokens(bigram, clean_text, token = "ngrams", n=2) %>%
  count(bigram, sort = TRUE) %>%
  filter(!str_detect(bigram, "good good")) %>%
  top_n(10) %>%
  ggplot(aes(x = reorder(bigram, n), y = n, collour = "aplikasi")) + 
  geom_col() + facet_wrap(~aplikasi, scales = "free_y") + coord_flip() + 
  labs( x = "Bigram", y = "Jumlah Bigram")
```

Gambar di atas menunjukkan term (dalam bentuk bigram) yang ada dalam data, di mana beberapa di antaranya digunakan baik dalam komentar yang diberikan oleh customer maupun dirver. Kata tersebut adalah adanya fitur chat dan penilaian terhadap aplikasi, yaitu term "good". 

Karena data ini merupakan komentar dibawah aplikasi, maka tidak heran jika banyak kata (bigram) juga tentang aplikasi, seperti go car, go food, dll. 

# Distribusi waktu data

Digunakan untuk mengetahui asal komentar berdasarkan waktu pembuatannya. 

```{r}
ps_gojek$date <- as.Date(ps_gojek$date)

ps_gojek %>%
  group_by(aplikasi) %>%
  count(date, sort = TRUE) %>% 
  ggplot(aes(x=date, y=n, colour=aplikasi)) +
  geom_line(show.legend = FALSE) +
  scale_x_date(labels = date_format("%Y-%m"), 
               breaks = date_breaks("2 months")) +
  facet_grid(aplikasi~., scales="free") + 
  labs(x = "Tahun - Bulan", y = "Jumlah Komentar")
  theme(legend.position="top")
```

Dari gambar di atas diketahi bahwa komentar terjauh diambil dari gojek untuk driver sekitar bulan 12 tahun 2016. Sementara data komentar untuk customer mayoritas berasal dari tahun 2018.

# TF-IDF berdasarkan aplikasi
Eksplorasi berikut digunakan untuk melihat kata terpenting berdasarkan nila tf-idf dari komentar untuk masing-masing aplikasi. 

```{r, echo=FALSE, fig.cap="TF-IDF untuk masing parameter"}
ps_words <- ps_gojek %>%
  select(aplikasi, clean_text) %>%
  group_by(aplikasi) %>%
  unnest_tokens(kata, clean_text, token = "ngrams", n = 2) %>%
  count(kata, sort = TRUE)

total_words <- ps_words %>% 
  group_by(aplikasi) %>% 
  summarize(total = sum(n))

ps_words <- left_join(ps_words, total_words)

ps_words <- ps_words %>%
  bind_tf_idf(kata, aplikasi, n) %>%
  arrange(desc(tf_idf))

# Visualisasi tf-idf
ps_words %>%
  arrange(desc(tf_idf)) %>%
  mutate(kata = factor(kata, levels = rev(unique(kata)))) %>% 
  group_by(aplikasi) %>% 
  top_n(10) %>% 
  ungroup %>%
  ggplot(aes(reorder(kata,tf_idf), tf_idf, fill = aplikasi)) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = "tf-idf") +
  facet_wrap(~aplikasi, ncol = 2, scales = "free") + 
  labs(x = NULL, y = "tf-idf trigram to Aplikasi") +
  coord_flip()
```

Dari gambar di atas diketahui bahwa berdasarkan komentar kustomer pada aplikasi gojek di playstore cenderung membicarakan penilaian yang direpresentasikan oleh term "good" yang juga berasosiasi dengan term "app" atau aplikasi. 

Sementara pada driver cendeung menekankan pentingnya fitur chat yang direpresentasikan oleh adanya term "chat". Menariknya, dalam komentar driver (mitra) juga muncul term "bad." Selain itu, driver juga melaporkan adanya penggunaan gitur "fake gps" yang mungkin merugikan mereka. 

# Semantic Network

Semantic network di sini dibuat berdasarkan posisi sebuah term dalam bigram. 

```{r, echo=FALSE, fig.cap="Semantic Network"}
bigram <- ps_gojek %>%
  select(clean_text) %>%
  unnest_tokens(bigram, clean_text, token = "ngrams", n = 2) %>%
  count(bigram, sort = TRUE) %>%
  separate(bigram, into = c("word1", "word2"))

bigram_graph <- bigram %>%
  filter(n > 25) %>%
  graph_from_data_frame()

ggraph(bigram_graph, layout = "fr") +
  geom_edge_link() +
  geom_node_point() +
  geom_node_text(aes(label = name), vjust = 1, hjust = 1)

```

# Topic Modelling

```{r, echo=FALSE}
# the LDA function using topicmodels package
bigram_tm <- function(input_text, # should be a columm from a dataframe
                       plot = T, # return a plot? TRUE by defult
                       number_of_topics = 4) # number of topics (4 by default)
{    
  set.seed(2016)
  # create a corpus (type of object expected by tm) and document term matrix
  Corpus <- VCorpus(VectorSource(input_text)) # make a VCorpus object spec for RWeka
  
  # function for creating bigram in the DTM
  BigramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min=2, max=2))
  # you can explore which term combination gave the most interpretable topic for you
  # by changing numbers inside Weka_control
  
  DTM <- DocumentTermMatrix(Corpus, control=list(tokenize=BigramTokenizer))
  
  # remove any empty rows in our document term matrix (if there are any 
  # we'll get an error when we try to run our LDA)
  unique_indexes <- unique(DTM$i) # get the index of each unique value
  DTM <- DTM[unique_indexes,] # get a subset of only those indexes
  
  # preform LDA & get the words/topic in a tidy text format
  lda <- LDA(DTM, k = number_of_topics, control = list(seed = 1234))
  topics <- tidy(lda, matrix = "beta")
  
  # get the top ten terms for each topic
  top_terms <- topics  %>% # take the topics data frame and..
    group_by(topic) %>% # treat each topic as a different group
    top_n(10, beta) %>% # get the top 10 most informative words
    ungroup() %>% # ungroup
    arrange(topic, -beta) # arrange words in descending informativeness
  
  # if the user asks for a plot (TRUE by default)
  if(plot == T){
    # plot the top ten terms for each topic in order
    top_terms %>% # take the top terms
      mutate(term = reorder(term, beta)) %>% # sort terms by beta value 
      ggplot(aes(term, beta, fill = factor(topic))) + # plot beta by theme
      geom_col(show.legend = FALSE) + # as a bar plot
      facet_wrap(~ topic, scales = "free") + # which each topic in a seperate plot
      labs(x = NULL, y = "Beta") + # no x label, change y label 
      coord_flip() # turn bars sideways
  }else{ 
    # if the user does not request a plot
    # return a list of sorted terms instead
    return(top_terms)
  }
}
```

Berikut ini adalah term dengan probabilitas tertinggi sebagai topik yang dibahas dalam twit tentang gojek.   

# Pemodelan Topik Komentar 
## Pelanggan

```{r, fig.cap="Hasil topic modelling"}
# execution
tm_ps_costum <- ps_gojek %>%
  filter(str_detect(aplikasi, "gojek_customer")) %>%
  select(date, clean_text, aplikasi)

tm_ps_gojek1 <- bigram_tm(tm_ps_costum$clean_text, number_of_topics = 2)
tm_ps_gojek
```

## Mitra

```{r}
tm_ps_mitra <- ps_gojek %>%
  filter(str_detect(aplikasi, "gojek_driver")) %>%
  select(date, clean_text, aplikasi)

tm_ps_gojek <- bigram_tm(tm_ps_mitra$clean_text, number_of_topics = 2)
tm_ps_gojek
```

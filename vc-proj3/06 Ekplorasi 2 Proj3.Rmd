---
title: 'Laporan 2: Twit tentang Teluk Benua'
author: "Ujang fahmi"
date: "4/30/2018"
output:
  html_notebook:
    number_sections: yes
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
  rmarkdown::pdf_document:
    fig_caption: yes
    includes:
      in_header: setup markdown.tex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, fig.pos = "h")

set.seed(2018)
```

# Pendahuluan
Berdasarkan hasil eksplorasi 1 pada twit yang memention akun @ChangeOrg_ID diketahui bahwa salah satu topik yang menjadi topik pembahasan warga net adalah tentang Teluk Benoa. Topik tersebut berkaiatan dengan penolakan warga net terhadap rencana reklamasi teluk benua di Bali. Oleh karena itu dalam eksplorasi 2 ini data yang digunakan adalah twit yang membahas tentang reklamasi tersebut. Twit dikumpulkan dengan metode semi automatic scrapping dengan dua parameter yaitu tagar **#balitolakreklamasi** dan **balinotforsale**. dua parameter tersebut menghasilkan twit sebanyak **72.640** dan **9.974** twit. Setelah dilakukan pengecekan konten duplikat didapat twit seperti dapat dilihat pada tabel di bawah ini. Jumlah twit tersebut kemudian akan digunakan dalam laporan ini. 

```{r}
# Runing RJava
if (Sys.info()['sysname'] == 'Darwin') {
  libjvm <- paste0(system2('/usr/libexec/java_home',stdout = TRUE)[1],'/jre/lib/server/libjvm.dylib')
  message (paste0('Load libjvm.dylib from: ',libjvm))
  dyn.load(libjvm)
}

library(tidyverse)
library(tidytext)
library(ggplot2)
library(stringr)
library(lubridate)
library(topicmodels)
library(tm)
library(RWeka)
library(reshape2)
library(wordcloud)
library(igraph)
library(ggraph)
library(quanteda)
library(googledrive)
library(textclean)
```


# Data

```{r}
id0 <- "1RAalTLYhpprDCpE_wos48ymufN8mjMG_" # twit-mention-change.csv 
id1 <- "11WTedaaE79EtT4vOGNU2vfG7xgcLtJcE" # twit-tagar-balitolakreklamasi.csv
id2 <- "1984jmFur63PmYvoC8Ab6P2iwfUQYVp71" # twit-tagar-balinotforsale.csv
id3 <- "1Pw0WZIuou9bw7nog1xCJqOVZDR-TCk88" # cleaned username_all 

twit_to_change <- read_csv(sprintf("https://docs.google.com/uc?id=%s&export=download", id0))
btr_raw <- read_csv(sprintf("https://docs.google.com/uc?id=%s&export=download", id1))
bns_raw <- read_csv(sprintf("https://docs.google.com/uc?id=%s&export=download", id2))
net_telukBenua <- read_csv(sprintf("https://docs.google.com/uc?id=%s&export=download", id3))
```


```{r}
#dirwd <- paste(getwd(),"/wrangled data proj-3/",sep='')
#btr_raw <- read_csv(paste(dirwd,"twit-tagar-balitolakreklamasi.csv",sep=''), col_names = TRUE)
#bns_raw <- read_csv(paste(dirwd,"twit-tagar-balinotforsale.csv",sep=''), col_names = TRUE)

tb_raw <- bind_rows(btr_raw, bns_raw)

tb_raw$tweets <- replace_white(tb_raw$tweets) # replacing white space
tb_raw$tweets <- replace_non_ascii(tb_raw$tweets, remove.nonconverted = TRUE)

# print is duplicate
tb_raw %>%
  group_by(is_duplicate) %>%
  count(is_duplicate) %>%
  summarise(n) %>%
  print()
```

Dari total **82.616** twit terdapat **13.603** twit yang merupakan twit duplikat atau memiliki konten yang sama. Oleh karena itu, dalam eksplorasi selanjutnya hanya akan menggunakan **69.013** twit. Distribusi twit tersebut dapat dilihat pada gambar di bawah ini.

```{r, fig.pos='h', fig.cap="Distribusi Twit yang menggunakan tagar bns atau btr"}
tb_raw <- tb_raw %>%
  filter(is_duplicate == FALSE)

tb_raw %>%
  group_by(date) %>% count(date) %>% arrange(date) %>%
  ggplot(aes(x = date, y = n)) + geom_line(show.legend = FALSE) + 
  labs(x = "Tahun", y = "Jumlah Twit")
```

Twit yang digunakan dalam laporan merupakan twit yang diunggah dengan tagar #balitolakreklamasi dan #balinotforsale dalam **6.5 tahun** terakhir. Twit pertama diunggah pada **2012-06-05**, sementara twit terakhir diunggah pada **2018-03-27**.

Twit dibagi menjadi tiga periode waktu sesuai dengan alur kejadian di darat. Periode 1 berasal dari twit yang diunggah dari 2012-06-05 sampai 2014-03-31. Periode 2 dari 2014-04-01 sampai 2014-08-31. Periode 3 dari 2014-09-01 sampai 2018-03-31. 

```{r}
tb_raw %>%
  group_by(parameter) %>%
  count(periode)
```

# Analisis Aktor
Aktor dalam twit merupakan username atau nama akun yang terdapat dalam twitter. Aktor dibedakan menjadi, yaitu aktor sebagai pengirim twit yang selanjutnya disebut pengirim dan aktor yang terlibat. Aktor yang terlibat juga dapat menjadi aktor pengirim twit, namun di sini aktor terlbat didapat dari body twit yang posisinya berada setelah akun pertama yang dianggap sebagai pengirim. 

## Akun pengirim
Akun pengirim twit yang mengandung dua tagar dapat dilihat pada gambar di bawah ini. Di mana dalam gambar dapat dilihat akun `ForBALI13` menjadi pengirim terbanyak. Akun tersebut merupakan akun resmi gerakan, sebagaimana dikonfirmasi oleh kordinator gerakan.

```{r, fig.cap="20 Akun pengirim twit terbanyak"}
tb_raw %>%
  filter(is_duplicate == FALSE) %>%
  count(user, sort = TRUE) %>%
  filter(!str_detect(user, 'ChangeOrg_ID')) %>%
  head(n = 20) %>%
  ggplot(aes(x = reorder(user, n), y = n)) + coord_flip() +
  geom_col(show.legend = FALSE) + 
  labs(x = "Username Twitter", y = "Jumlah Twit yang dikirim")
```
Selain akun `ForBALI13` juga terdapat beberapa akun lain yang cukup banyak mengirimkan twit tentang tolak reklamasi teluk benoa. Akun-akun tersebut juga rata-rata memiliki follower cukup banyak. Hal ini membuat twit tentang tolak reklamasi menyebar cukup cepat. Hal ini juga menjadi salah satu strategi gerakan dengan melibatkan "artis" atau aktor yang telah lebih dulu populer. Sebagai contoh, JRX_SID yang juga merupakan anggota band SID memiliki 364 ribu lebih follower Twitter. 

## Akun terlibat
Gambar di bawah ini menunjukkan akun-akun yang terlibat atau yang berada dalam twit (termasuk akun pengirim). Di mana selain akun-akun yang juga muncul dalam daftar pengirim twit juga terdapat akun lain yang juga cukup populer seperti akun `@SBYudhoyono` dan `@jokowi`. 

```{r, fig.cap="20 Akun yang paling sering dimention"}
net_telukBenua %>%
  unnest_tokens(user, Data, to_lower = FALSE) %>%
  count(user, sort = TRUE) %>%
  filter(!str_detect(user, 'ChangeOrg_ID')) %>%
  head(n = 20) %>%
  ggplot(aes(x = reorder(user, n), y = n)) + coord_flip() +
  geom_col(show.legend = FALSE) + 
  labs(x = "Username Twitter", y = "Jumlah Keberadaan Username dalam Twit")
```

Gambar di atas menunjukkan bahwa dalam twit terdapat dua kelompok akun yang popler. *Pertama* akun yang juga muncul dalam daftar pengirim atau juga dapat dikategorikan sebagai pendukung gerakan. *Kedua* kelompok akun yang menjadi "sasaran" dari gerakan, termasuk akun menteri Susi (menteri kelautan dan lingkungan hidup) yang berkaitan dengan pemberian izin reklamasi. Adanya dua kelompok tersebut dapat menginfirmasi asumsi tentang penggunaan media sosial sebagai media komunikasi antara masyarakat dengan pemerintah. Dalam konteks gerakan, hal tersebut juga menjadi salah satu penyuaraan kepentingan dan "preferensi" publik.

## Social network analysis
Network analysis dilakukan melalui perangkat lunak gephi, termasuk perhitungan komponen dari network seperti modularity, dan centrality. Di mana `nodes` merupakan username Twitte dan `edges` merupakan keberadaan dalam twit yang sama atau `cooccurrance`. 
![Network Teluk Benoa](/Volumes/mydata/RStudio/virtualCitizens/vc-proj3/wrangled data proj-3/teluk benoa network.png)
**Keterangan:** Warna dalam gambar dibuat berdasarkan *modularity class* dan besar nodes dibuat berdasarkan *eigenvector centrality*. Gambar hanya menampilkan nodes dengan minimum degree 20. 

Gambar di bawah ini menunjukkan bahwa pengguna twitter tidak memiliki perbedaan yang cukup mencolok karena masing-masing akun berada cukup berdekatan satu sama lain. Di satu sisi hal tersebut dapat menjadi indikator positif yang menunjukkan adanya kesamaan pandangan tentang reklamasi. Di sisi lain, keberadaannya yang cukup berdekatan tersebut juga menjadi salah satu indikator adanya satu aktor kunci yang cukup dominan. Hal tersebut bukan hal yang buruk, namun ketika terjadi akun tersebut berhenti dapat memengaruhi gerakan secara keseluruhan. Gambar berikut menunjukkan posisi 10 akun dengan `eigencentrality` tertinggi.

```{r}
id4 <- "1WImYxfSR8Nzutfv8ZV74Xa_O2GTZ2zye" # network analysis
net_analysis <- read_csv(sprintf("https://docs.google.com/uc?id=%s&export=download", id4))

net_analysis %>%
  select(Label, eigencentrality) %>%
  arrange(desc(eigencentrality)) %>%
  head(n = 10) %>%
  ggplot(aes(reorder(Label, eigencentrality), eigencentrality)) + 
  coord_flip() + geom_col() + 
  labs(x = "Nama Akun", y = "eigencentrality")
```

Tiga akun pertama dalam gambar di atas merupakan akun dengan eigencentrality tertinggi dalam jaringan. Artinya, akun-akun tersebut memiliki kecenderungan untuk terhubung dengan aktor-aktor (username) lain yang juga penting **(lihat: konsep eigencentrality)**. Sehingga secara matematis juga dapat disimpulkan bahwa akun tersebut memiliki pengetahuan dan mungkin menjadi penggerak dalam jaringan gerakan bali tolak reklamasi. Sementara dua akun di bawahnya yang juga diketahui merupakan akun resmi milik mantan presiden dan presiden saat ini mengindikasikan bahwa kasus penolakan reklamasi mencoba untuk dibawa menjadi ketingkat tertinggi pemerintahan, yaitu presiden. Dengan kata lain, isu ini mencoba dibawa menjadi isu nasional dengan menggunakan media sosial. 

Kenapa media sosia? dapat dijawab dengan data dari media serta hasil wawancara dengan **gendovara**.

# Analisis Konten
Analisis konten **twit** atau tulisan yang diunggah oleh warga net melalui media sosial **Twitter** dapat dilakukan melalui beberapa tahapan. Tahap pertama dapat dilakukan melalui tagar atau tanda pagar (en: *hashtag*). Gambar di bawah ini menunjukkan beberapa tagar yang digunakan dalam setiap periode.  

## Tagar
Tagar merupakan salah satu indikator utama yang dapat digunakan untuk melihat sebuah konten media sosial. Dalam hal ini, tagar sering digunakan oleh pengguna media sosial sebagai penanda sebuah pembahasan, termasuk dalam Twitter. 

```{r, fig.cap="Tagar yang digunakan"}
tagar_periode1 <- tb_raw %>%
  filter(periode == "periode_1") %>%
  select(hashtag, tag_count) %>%
  filter(tag_count >= 1) %>%
  unnest_tokens(tagar, hashtag) %>%
  count(tagar, sort = TRUE)

tagar_periode2 <- tb_raw %>%
  filter(periode == "periode_2") %>%
  select(hashtag, tag_count) %>%
  filter(tag_count >= 1) %>%
  unnest_tokens(tagar, hashtag) %>%
  count(tagar, sort = TRUE)

tagar_periode3 <- tb_raw %>%
  filter(periode == "periode_3") %>%
  select(hashtag, tag_count) %>%
  filter(tag_count >= 1) %>%
  unnest_tokens(tagar, hashtag) %>%
  count(tagar, sort = TRUE)

tagar_periode <- bind_rows(tagar_periode1 %>%
                             mutate(periode = "periode_1"), 
                           tagar_periode2 %>%
                             mutate(periode = "periode_2"), 
                           tagar_periode3 %>%
                             mutate(periode = "periode_3"))

tagar_periode %>%
  #filter(!str_detect(tagar, 'balitolakreklamasi')) %>%
  #filter(!str_detect(tagar, 'balinotforsale')) %>%
  filter(!str_detect(tagar, 'tolakreklamasi')) %>%
  filter(!str_detect(tagar, 'nw')) %>%
  filter(!str_detect(tagar, 'np')) %>%
  filter(!str_detect(tagar, 'ff')) %>%
  filter(!str_detect(tagar, 'indonesia')) %>%
  filter(!str_detect(tagar, 'repost')) %>%
  filter(!str_detect(tagar, 'share')) %>%
  filter(!str_detect(tagar, 'bali')) %>%
  filter(!str_detect(tagar, '2')) %>%
  filter(!str_detect(tagar, '1')) %>%
  filter(!str_detect(tagar, '4')) %>%
  filter(!str_detect(tagar, '5')) %>%
  filter(!str_detect(tagar, '3')) %>%
  group_by(periode) %>%
  top_n(15, n) %>%
  ggplot(aes(reorder(tagar, n), n, fill = periode)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ periode, scales = "free", ncol = 3) +
  coord_flip() +
  labs(x = "Tagar", 
       y = "Jumlah twit yang diunggah")
```

Gambar di atas menunjukkan tagara (kecuali tagar balitolakreklamasi dan balinotforsale) yang menjadi **parameter** mendapatkan data. Asumsinya, ketia dua tagar tersebut digunakan akan menjadi terlalui dominan dalam visualisasi karena semua twit menggunakan tagar tersebut. Selain dua tagar tersebut terdapat beberapa tagar lain yang juga tidak diikutsertakan karena dianggap tidak relevan, misalnya tagar repost, share, dan beberapa angka yang tidak memiliki arti seperti 1, 2, 3 dst. 

Secara umum tagar-tagar yang digunakan oleh pengguna Twitter mengalami perkembangan dari waktu ke waktu. Hal ini sejalan dengan salah satu pernyataan dari nara sumber yang mengatakan bahwa tagar yang digunakan dipilih dan disesuaikan dengan momen yang berkembang saat itu. Bali not for sale sendiri telah lebih dulu digunakan dibanding tagar balitolakreklamasi, dan setelahnya tagar terus berkembang hingga pada akhir periode ada juga tagar **#kecewaamasusi**. Tagar kecewaamasusi diantaranya dapat dilihat pada twit-twit berikut ini. 

```{r}
tb_raw %>%
  filter(is_duplicate == FALSE) %>%
  filter(str_detect(tweets, "#KecewaAmaSusi")) %>%
  arrange(desc(ret_count)) %>%
  select(tweets) %>%
  head(n = 5) %>% 
  print()
```

Twit di atas menunjukkan twit-twit yang memiliki tagar #KecewaAmaSusi dan diurutkan berdasarkan jumlah retweet terbanyak. Isi dari twit secara seklias dapat menggambarkan bahwa twit diunggah sebagai respons terhadap sikap menteri Susi terkait dengan reklamasi yang mereka hadapi. Selain itu, di sana juga mereka menyatakan bahwa pilihannya hanya menolak reklamasi. 

Kasus ini sendiri muncul karena pada waktu itu, ijin reklamasi akan segara habis dan harus mendapat perpanjangan ijin. Pemeberian ijin menjadi salah satu kewenangan yang dapat diberikan oleh menteri kelautan, yaitu Susi. Namun, menurut penuturan salah seorang partisipan menteri tersebut memilih untuk diam, sehingga secara otomatis ijin pun berlanjut. Karena hal tersebutlah kemudian mereka membuat tagar **#KecewaAmaSusi**. 

## Term
Term atau kata diambil dari isi twit selain usernme dan tagar. Gambar di bawah ini menunjukkan term dalam bentuk bigram. Di mana bigram dibuat berdasarkan keberadaan term dalam twit yang sama. Misalnya, sebuah twit berisi kalimat **"aku suka makan nasi"** maka bigram yang dapat dibuat dari kalimat tersebut adalah **"aku suka"**, **"suka makan"**, dan **"makan nasi."** 

```{r, fig.cap="Frekuensi Bigram dalam twit"}
tb_raw %>%
  filter(is_duplicate == FALSE) %>%
  filter(word_count >= 2) %>%
  select(date, clean_text, word_count, periode) %>%
  unnest_tokens(kata, clean_text, token = "ngrams", n = 2) %>%
  count(kata, sort = TRUE) %>%
  head(n = 20) %>%
  ggplot(aes(reorder(kata, n), n)) + geom_col() + coord_flip() +
  labs(x = "bigram", y = "jumlah bigram")
```

Pasangan kata yang paling banyak muncul dari twit dengan dua tagar yang jadi parameter adalah konser mini. Hal tersebut menunjukkan bahwa dua kata tersebut rutin di gunakan oleh pengguna twitter. Selain itu, berdaraskan frekuensinya, pasangan kata yang muncul selanjutnya adalah metro dan tv, yang menujukkan sebuah stasiun tv nasional. Penyebab dua kata tersebut sering muncul kemungkinan besar dipicu oleh adanya acara yang mengundang tokoh/aktor gerakan bali tolak reklamasi. Pasangan kata berikutnya adalah perpres limasatu yang merujuk pada perpres no 51 tahun 2014 tentang reklamasi teluk benoa. Kemunculan kata ini secara tidak langsung telah mengonfirmasi bahwa twit yang digunakan berisi pendapat warga net seputar reklamasi teluk benoa. 

Kata atau pasangan kata berikutnya juga dapat dinterpretasikan dengan pola yang sama, yaitu dengan merujuk pada cerita baik yang didapat dari data darat. Interpretasi juga dapat dilakukan dengan merujuk pada hasil `close reading` twit aktor utama. 

## Semantic network
Selain dengan bigram di atas, hubungan antar kata dari sebuah korpus juga dapat dilihat melalui semantic network. Di mana satu term memiliki hubungan dengan term lain berdasarkan keberadaannya. Gambar di bawah ini menunjukkan hubungan antar term yang terjadi minimal 100 kali. 

```{r, fig.cap= "Word network dalam twit yang menggunakan tagar bns atau btr"}
bigram_counts <- tb_raw %>%
  filter(is_duplicate == FALSE) %>%
  filter(word_count >= 2) %>%
  select(clean_text) %>%
  unnest_tokens(bigram, clean_text, token = "ngrams", n = 2) %>%
  count(bigram, sort = TRUE) %>%
  separate(bigram, into = c("word1", "word2"))

library(widyr)

bigram_counts %>%
  filter(n >= 100) %>%
  graph_from_data_frame() %>%
  ggraph(layout = "fr") +
  geom_edge_link(aes(edge_alpha = n, edge_width = n), edge_colour = "cyan4") +
  geom_node_point(size = 5) +
  geom_node_text(aes(label = name), repel = TRUE, 
                 point.padding = unit(0.2, "lines")) +
  theme_void()
```

Dari gambar di atas kita dapat mengetahui bahwa gerakan telah diliput oleh tv, diantaranya adalah oleh metro dan kompas tv. Hal ini ditunjukkan oleh munculnya tiga kata tersebut dalam satu jaringan yang sama. Untuk menginfirmasi hal ini, kita dapat melihatnya secara langsung dalam isi twit berikut. 

**Twit dengan kata kunci tv**
```{r}
tb_raw %>%
  filter(is_duplicate == FALSE) %>%
  filter(str_detect(tweets, "Tv")) %>%
  arrange(desc(ret_count)) %>%
  select(tweets) %>%
  head(n = 5) %>% 
  print()
```
**Twit dengan kata kunci kompas tv**
```{r}
tb_raw %>%
  filter(is_duplicate == FALSE) %>%
  filter(str_detect(tweets, "Kompas TV")) %>%
  arrange(desc(ret_count)) %>%
  select(tweets) %>%
  head(n = 5) %>% 
  print()
```

## Tf-idf
Penjelasan tentang TF-IDF secara umum dapat ditemukan di sini. Secara umum TF-IDF merupakan sebuah upaya untuk menemukan term yang penting dalam sebuah dokumen dengan membandingkan frekuensi dalam dokumen yang spesifik dengan frekuensi dalam dokumen secara umum. Sebagai ilustrasi, kita dapat menemukan term yang hampir pasti memiliki frekuensi yang tinggi dalam setiap dokumen, misalnya kata di, dan dan dalam. Kata-kata tersebut sering disebut *stopwords*. Namun karena kata tersebut tidak bersifat unik, dan juga ada dalam dokumen yang lain, maka nilai tf-idfnya akan turun. Sebaliknya, jika sebuah term memiliki frekuensi tinggi dalam sebuah dokumen dan tidak dalam dokumen yang lain, kata atau term tersebut akan memiliki nilai yang tinggi. Gambar di bawah ini, menunjukkan kata-kata dengan tf-idf tertinggi dalam setiap periode. 

```{r, fig.cap="TF-IDF bigram per periode"}
twit_words <- tb_raw %>%
  filter(is_duplicate == FALSE) %>%
  filter(word_count >= 2) %>%
  select(clean_text, periode) %>%
  group_by(periode) %>%
  unnest_tokens(kata, clean_text, token = "ngrams", n = 2) %>%
  count(kata, sort = TRUE)

total_words <- twit_words %>% 
  group_by(periode) %>% 
  summarize(total = sum(n))

twit_words <- left_join(twit_words, total_words)

twit_words <- twit_words %>%
  bind_tf_idf(kata, periode, n) %>%
  arrange(desc(tf_idf))

# Visualisasi tf-idf
twit_words %>%
  arrange(desc(tf_idf)) %>%
  mutate(kata = factor(kata, levels = rev(unique(kata)))) %>% 
  group_by(periode) %>% 
  top_n(10) %>% 
  ungroup %>%
  ggplot(aes(reorder(kata,tf_idf), tf_idf, fill = periode)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~periode, ncol = 2, scales = "free") + 
  labs(x = "Bigram", y = "Value") +
  coord_flip()
```

Gambar di atas menunjukkan kata atau pasangan kata yang dianggap lebih penting dibanding kata lainnya dalam setiap periode. Pada periode pertama kata terpentingnya adalah **"dprd berperang."** Jika merujuk pada twit yang mengandung kata tersebut, makan kata **dprd berperang** dapat diinterpretasikan sebagai upaya perlawanan masyarakat Bali untuk menolak reklamasi teluk benoa dengan cara berdemonstrasi di gedung dprd Bali. Hal tersebut dapat dilihat dalam beberapa twit di bahwah ini. 

```{r}
tb_raw %>%
  filter(is_duplicate == FALSE) %>%
  filter(periode == "periode_1") %>%
  filter(!str_detect(tweets, "RT")) %>%
  filter(str_detect(clean_text, "dprd berperang")) %>%
  select(tweets) %>%
  head(n = 5) %>% 
  print()
```
Sementara dalam periode dua, kita menemukan term yang cukup unik yaity **ve fooled**. Tanpa membaca lebih jauh term tersebut susah untuk diinterpretasikan. Untuk itu, beberapa twit di bawah ini mungkin dapat memberikan gambaran tentang isi twit dengan kata tersebut. 

```{r}
tb_raw %>%
  filter(is_duplicate == FALSE) %>%
  filter(periode == "periode_2") %>%
  filter(!str_detect(tweets, "RT")) %>%
  arrange(desc(ret_count)) %>%
  filter(str_detect(clean_text, "ve fooled")) %>%
  select(tweets) %>%
  head(n = 5) %>% 
  print()
```
Dari twit di atas, ternyata term **ve fooled** berkaitan dengan keberadaan Cristiano Ronaldo ke Bali. Term ve sendiri ternyata berasal dari 've fooled atau u've been fooled. Dengan kata lain, melalui term tersebut kita dapat mengetahui bahwa warga net menganggap Cristiano telah dibohongi oleh akun yang juga ditunjukkan dalam twit tersebut.

Kata terpenting dari periode ketiga adalah **art event.** Term ini berkaitan dengan kegiatan yang dilakukan untuk menyuarakan penolakan reklamasi. Hal ini tercermin dalam twit di bawah ini. 

```{r}
tb_raw %>%
  filter(is_duplicate == FALSE) %>%
  filter(periode == "periode_3") %>%
  filter(!str_detect(tweets, "RT")) %>%
  arrange(desc(ret_count)) %>%
  filter(str_detect(clean_text, "art event")) %>%
  select(tweets) %>%
  head(n = 5) %>% 
  print()
```


## Topic Modelling
Topic modelling di sini dibagi menjadi tiga bagian berdasarkan periode waktu twit diunggah. Namun sebelumnya terlebih dahulu akan dilihat topic secara umum dari data. Topik-topik yang muncul per periode selanjutnya dapat dilihat pada gambar-gambara di bawah ini. Untuk keterangan lebih lanjut dengan topic modelling dengan algoritme LDA dapat dilihat [di sini](http://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf). 

```{r}
# the LDA function using topicmodels package
bigram_tm <- function(input_text, 
                       plot = T, 
                       number_of_topics = 4)
{    
  set.seed(2016)
  Corpus <- VCorpus(VectorSource(input_text))
  
  BigramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min=2, max=2))
  DTM <- DocumentTermMatrix(Corpus, control=list(tokenize=BigramTokenizer))
  unique_indexes <- unique(DTM$i)
  DTM <- DTM[unique_indexes,]
  lda <- LDA(DTM, k = number_of_topics, control = list(seed = 1234))
  topics <- tidy(lda, matrix = "beta")
  top_terms <- topics  %>% 
    group_by(topic) %>% 
    top_n(10, beta) %>%
    ungroup() %>%
    arrange(topic, -beta)
  
  # if the user asks for a plot (TRUE by default)
  if(plot == T){
    top_terms %>%
      mutate(term = reorder(term, beta)) %>% 
      ggplot(aes(term, beta, fill = factor(topic))) +
      geom_col(show.legend = FALSE) + 
      facet_wrap(~ topic, scales = "free") +
      labs(x = NULL, y = "Beta") + 
      coord_flip()
  }else{ 
    # if the user does not request a plot
    # return a list of sorted terms instead
    return(top_terms)
  }
}
```

### Topic modelling all

Di dalam analisis ini twit yang digunakan hanya 55067, karena sebelumnya telah dilakukan beberapa filterisasi. Pertama, twit yang memiliki konten yang sama dihilangkan, kedua, twit yang setelah dilakukan cleaning hanya memiliki satu *term* dan atau koosong juga dihilangkan. Sehingga topic modelling dihasilkan dari twit yang memiliki minimal dua *term* setelah cleaning. 

- filter = wordcount >= 2
- total twit = **55067**

```{r, fig.cap="Topic modelling dari seluruh twit"}
set.seed(2018)
# taking data for topic modelling
tm_teluk_benoa <- tb_raw %>%
  select(date, user,clean_text, word_count, parameter) %>%
  filter(word_count >= 2)

# topic modelling
tm_twit <- bigram_tm(tm_teluk_benoa$clean_text, number_of_topics = 4)
tm_twit
```

**Topik 1 - aksi demonstrasi**

Gambar nomor satu menunjukkab beberapa topik terkait dengan penolakan reklamasi teluk benoa di Balik. Di sini kita dapat melihat bahwa salah satu aksi dilakukan dengan cara melakukan demonstrasi di kantor **DPRD BALI**. Beberapa warga net juga menganggap aksi mereka sebagai upaya memerangi penguasa dan pengusaha yang berupaya melakukan/mendukung reklamasi dilakukan. Di sisi lain, mereka menganggap reklamasi akan merusak alam yang seharusnya dilestarikan. Hal tersebut tercermin dalam twit-twit yang menggunakan tagar balinotforsale dan atau balitolakreklamasi. Contoh twit dari periode tersebut adalah sebagai berikut: 

```{r}
tb_raw %>%
  filter(is_duplicate == FALSE) %>%
  filter(periode == "periode_1") %>%
  filter(!str_detect(tweets, "RT")) %>%
  arrange(desc(ret_count)) %>%
  select(tweets) %>%
  head(n = 5) %>% 
  print()
```


**Topik 2 - konsolidasi aksi dan representasi aski**


**Topik 3 - objek yang ditolak**


**Topik 4 - pernyataan sikap melalui aksi**


```{r}
tb_raw %>%
  filter(is_duplicate == FALSE) %>%
  filter(str_detect(clean_text, "kantor dprd")) %>%
  select(tweets) %>%
  head(n = 5) %>% 
  print()
```


### Topic modelling periode 1
- filter = wordcount >= 2
- total twit = 15209
```{r, fig.cap="Topic modelling dari twit tentang Teluk Benoa periode 1"}
# taking data for topic modelling
tm_tb_periode1 <- tb_raw %>%
  filter(periode == "periode_1") %>%
  select(date, user,clean_text, word_count, parameter) %>%
  filter(word_count >= 2)

# topic modelling
tm_tb_p1 <- bigram_tm(tm_tb_periode1$clean_text, number_of_topics = 4)
tm_tb_p1
```

```{r}
tb_raw %>%
  filter(is_duplicate == FALSE) %>%
  filter(periode == "periode_1") %>%
  filter(str_detect(clean_text, "konser mini")) %>%
  select(tweets) %>%
  head(n = 5) %>% 
  print()
```




### Topic modelling periode 2
- filter = wordcount >= 2
- total twit = 17186

```{r, fig.cap="Topic modelling dari twit tentang Teluk Benoa periode 1"}
# taking data for topic modelling
tm_tb_periode2 <- tb_raw %>%
  filter(periode == "periode_2") %>%
  select(date, user,clean_text, word_count, parameter) %>%
  filter(word_count >= 2)

# topic modelling
tm_tb_p2 <- bigram_tm(tm_tb_periode2$clean_text, number_of_topics = 4)
tm_tb_p2
```

**Batalkan perpres**
```{r}
tb_raw %>%
  filter(is_duplicate == FALSE) %>%
  filter(periode == "periode_2") %>%
  filter(str_detect(clean_text, "batalkan perpres")) %>%
  select(tweets) %>%
  head(n = 5) %>% 
  print(tweets)
```

**Dukung gerakan**

```{r}
tb_raw %>%
  filter(is_duplicate == FALSE) %>%
  filter(periode == "periode_2") %>%
  filter(str_detect(clean_text, "dukung gerakan")) %>%
  select(tweets) %>%
  head(n = 5) %>% 
  print(tweets)
```

### Topic modelling periode 3

- filter = wordcount >= 2
- total twit = 22672

```{r, fig.cap="Topic modelling dari twit tentang Teluk Benoa periode 1"}
# taking data for topic modelling
tm_tb_periode3 <- tb_raw %>%
  filter(periode == "periode_3") %>%
  select(date, user,clean_text, word_count, parameter) %>%
  filter(word_count >= 2)

# topic modelling
tm_tb_p3 <- bigram_tm(tm_tb_periode3$clean_text, number_of_topics = 4)
tm_tb_p3
```

# Penutup

## Simpulan
periode 1 - konser untuk mempopulerkan keresahan tentang tolak reklamasi bali 
periode 2 - 

